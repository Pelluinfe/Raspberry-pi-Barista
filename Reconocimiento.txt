import cv2
import os
import numpy as np
import RPi.GPIO as GPIO
import time


GPIO.setup(pin,GPIO.OUT)
pwm_1=GPIO.PWM(pin,100) # pin 24 y divide en frecuencia de 1/100 un segundo (10[ms])


dataPath = '/home/omarpi/Desktop/proyectos Python/Imagenometria/Data/' #Cambia a la ruta donde hayas almacenado Data
imagePaths = os.listdir(dataPath)
print('imagePaths=',imagePaths)

face_recognizer = cv2.face.LBPHFaceRecognizer_create()

# Leyendo el modelo
face_recognizer.read("/home/omarpi/Desktop/proyectos Python/Imagenometria/Modelo/modeloEigenFace.xml")

imagePaths= os.listdir(dataPath)
print('imagePaths=',imagePaths)

### INICIO RECONOCIMIENTO FACIAL
cap=cv2.VideoCapture(0)

faceClassif = cv2.CascadeClassifier(cv2.data.haarcascades+"haarcascade_frontalface_default.xml")

while True:
    ret,frame =cap.read()
    if ret == False:
        variable = None
        break
    frame_1 = cv2.resize(frame, (510,340)) # re zise video


    # Gardamos en la variable frame el nuevo escalado de la imagen que centra la imagen
    frame = frame_1[:,round(len(frame_1[0])/4):round(3*len(frame_1[0])/4)] # imagen para solo reconocer la parte de al medio
    
    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)
    auxFrame = gray.copy()

    faces = faceClassif.detectMultiScale(gray,1.3,5)
    

    for(x,y,w,h) in faces:
        rostro = auxFrame[y:y+h,x:x+w]
        rostro = cv2.resize(rostro,(150,150),interpolation=cv2.INTER_CUBIC)
        result = face_recognizer.predict(rostro)

        cv2.putText(frame,'{}'.format(result),(x,y-5),1,.8,(20,20,20),1,cv2.LINE_AA)

        #EigenFaces
        if result[1]<5700:
            cv2.putText(frame,'{}'.format(imagePaths[result[0]]), (x,y-25), 1, 1, (200,100,100), 1, cv2.LINE_AA)
            cv2.rectangle(frame, (x,y), (x+w,y+h), (0,255,0), 1)
            variable = '{}'.format(imagePaths[result[0]])
        else:
            cv2.putText(frame,'Desconocido', (x,y-20), 1, 1, (200,100,100), 1, cv2.LINE_AA)
            cv2.rectangle(frame, (x,y), (x+w,y+h), (0,255,0), 1)


    l = int((frame_1.shape[1]-frame.shape[1])/2)
    frame_2=cv2.cvtColor(cv2.cvtColor(frame_1,cv2.COLOR_BGR2GRAY),cv2.COLOR_GRAY2BGR)

    frame_2[:,l:frame.shape[1]+l] =frame
    cv2.rectangle(frame_2, (l,0), (frame.shape[1]+l,frame.shape[0]), (255,255,250), 2)

    cv2.imshow('output',frame_2)
    cv2.imshow('reconocimiento',frame)
    k = cv2.waitKey(30)
    if k == 27: # Tecla 'Esc'
        break
    
    #variable : almacena el dato final
# Terminamos PWM
#Libreamos la camara y cerramos todas las ventanas
cap.release()
cv2.destroyALLWindows()
